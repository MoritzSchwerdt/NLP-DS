{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-13T08:19:11.252200200Z",
     "start_time": "2023-07-13T08:19:11.225415900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def calculate_cascade_metrics(tweets):\n",
    "    # Group tweets by conversation\n",
    "    conversations = defaultdict(list)\n",
    "    for tweet in tweets:\n",
    "        conversations[tweet['conversation_id']].append(tweet)\n",
    "\n",
    "    # Calculate cascade size, depth, and width for each conversation\n",
    "    cascade_sizes = {}\n",
    "    cascade_depths = {}\n",
    "    cascade_widths = {}\n",
    "    for conversation_id, tweets in conversations.items():\n",
    "        # Unique authors represent the size\n",
    "        authors = set(tweet['author_id'] for tweet in tweets)\n",
    "        cascade_sizes[conversation_id] = len(authors)\n",
    "\n",
    "        # Depth is approximated by the number of tweets that are replies\n",
    "        depths = [tweet for tweet in tweets if 'in_reply_to_user_id' in tweet]\n",
    "        cascade_depths[conversation_id] = len(depths)\n",
    "\n",
    "        # Width is approximated by the maximum number of authors at any \"depth level\"\n",
    "        depth_authors = defaultdict(set)\n",
    "        for tweet in tweets:\n",
    "            if 'in_reply_to_user_id' in tweet:\n",
    "                depth_authors[tweet['in_reply_to_user_id']].add(tweet['author_id'])\n",
    "        if depth_authors:  # handle case where there are no replies\n",
    "            cascade_widths[conversation_id] = max(len(authors) for authors in depth_authors.values())\n",
    "        else:\n",
    "            cascade_widths[conversation_id] = 0  # no replies means width is 0\n",
    "\n",
    "    return cascade_sizes, cascade_depths, cascade_widths\n",
    "\n",
    "def calculate_virality(tweets):\n",
    "    # Virality is the sum of retweet_count and like_count\n",
    "    virality = {}\n",
    "    for tweet in tweets:\n",
    "        metrics = tweet['public_metrics']\n",
    "        virality[tweet['id']] = metrics['retweet_count'] + metrics['like_count']\n",
    "    return virality"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T08:19:11.267577Z",
     "start_time": "2023-07-13T08:19:11.252715100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def process_directory(directory):\n",
    "    results = []\n",
    "    all_virality = {}  # store all virality scores\n",
    "\n",
    "    # First pass: calculate metrics and collect all virality scores\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(directory, filename), \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            cascade_sizes, cascade_depths, cascade_widths = calculate_cascade_metrics(data)\n",
    "            virality = calculate_virality(data)\n",
    "\n",
    "            all_virality.update(virality)\n",
    "\n",
    "            # Identify the tweets/conversations with the highest values for each metric\n",
    "            biggest_conversations = max(cascade_sizes, key=cascade_sizes.get)\n",
    "            biggest_cascade_depths = max(cascade_depths, key=cascade_depths.get)\n",
    "            biggest_cascade_widths = max(cascade_widths, key=cascade_widths.get)\n",
    "            biggest_virality = max(virality, key=virality.get)\n",
    "\n",
    "            # Prepare the output\n",
    "            output = {\n",
    "                \"hashtag\": filename.rstrip(\".json\"),\n",
    "                \"biggest_conversations\": [{\"conversation_id\": biggest_conversations, \"size\": cascade_sizes[biggest_conversations]}],\n",
    "                \"biggest_cascade_depth\": [{\"tweet_id\": biggest_cascade_depths, \"value\": cascade_depths[biggest_cascade_depths]}],\n",
    "                \"biggest_cascade_size\": [{\"tweet_id\": biggest_conversations, \"value\": cascade_sizes[biggest_conversations]}],\n",
    "                \"biggest_cascade_breadth\": [{\"tweet_id\": biggest_cascade_widths, \"value\": cascade_widths[biggest_cascade_widths]}],\n",
    "                \"biggest_cascade_virality\": [{\"tweet_id\": biggest_virality, \"value\": virality[biggest_virality]}]\n",
    "\n",
    "            }\n",
    "            results.append(output)\n",
    "\n",
    "    # Second pass: normalize virality scores\n",
    "    max_virality = max(all_virality.values())\n",
    "    for result in results:\n",
    "        for tweet in result[\"biggest_cascade_virality\"]:\n",
    "            tweet[\"value\"] /= max_virality\n",
    "\n",
    "    # Save the results to a new JSON file\n",
    "    with open(\"analysis_results.json\", \"w\") as file:\n",
    "        json.dump(results, file, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T08:19:11.283448700Z",
     "start_time": "2023-07-13T08:19:11.263608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "process_directory(\"data\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T08:19:13.931095300Z",
     "start_time": "2023-07-13T08:19:11.275015600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T08:19:13.946966900Z",
     "start_time": "2023-07-13T08:19:13.933078500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
